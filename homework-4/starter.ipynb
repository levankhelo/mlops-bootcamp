{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c51efaa",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn @ file:///private/var/folders/c_/qfmhj66j0tn016nkx_th4hxm0000gp/T/abs_4bu2zqzzh9/croot/scikit-learn_1714164755228/work\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4acf73a0-51b5-4663-9bb8-8eb947863e17",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.4\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ef880a0",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7836ccfd",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/levan/anaconda3/lib/python3.12/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DictVectorizer from version 1.5.0 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/levan/anaconda3/lib/python3.12/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LinearRegression from version 1.5.0 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('model.bin', 'rb') as f_in:\n",
    "    dv, model = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41c08294",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "\n",
    "\n",
    "def read_data(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df['duration'] = df.duration.dt.total_seconds() / 60\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)].copy()\n",
    "\n",
    "    df[categorical] = df[categorical].fillna(-1).astype('int').astype('str')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4854399a",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df = read_data('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-03.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "669fda0a",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "dicts = df[categorical].to_dict(orient='records')\n",
    "X_val = dv.transform(dicts)\n",
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d32b0d4a",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1. Notebook. standard deviation: 6.249106352794334\n"
     ]
    }
   ],
   "source": [
    "deviation = abs(df['duration'] - y_pred)\n",
    "mean_deviation = deviation.mean()\n",
    "print(f\"Q1. Notebook. standard deviation: {mean_deviation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "31941348",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#Create new dataframe with ride_id column and write in new file\n",
    "year = 2024  # Assuming the dataset is for 2024\n",
    "month = 3    # March as indicated in the filename\n",
    "\n",
    "df['ride_id'] = f'{year:04d}/{month:02d}_' + df.index.astype('str')\n",
    "\n",
    "# Prepare the dataframe\n",
    "df_result = pd.DataFrame({\n",
    "    'ride_id': df['ride_id'],\n",
    "    'predicted_duration': y_pred\n",
    "})\n",
    "\n",
    "# Create new file\n",
    "output_file = 'yellow_tripdata_2024-03_with_ride_id.parquet'\n",
    "\n",
    "df_result.to_parquet(\n",
    "    output_file,\n",
    "    engine='pyarrow',\n",
    "    compression=None,\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "13aef114",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2: preparing the output. file size: 68.93 MB\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Check the size of the output file\n",
    "import os\n",
    "\n",
    "file_size = os.path.getsize(output_file) / (1024 * 1024)  # Convert bytes to MB\n",
    "print(f\"Q2: preparing the output. file size: {file_size:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "821c669a",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list --format=freeze > requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
